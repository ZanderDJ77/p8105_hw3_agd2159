---
title: "P8015_Hw3_agd2159"
output: github_document
author: "Zander De Jesus"
date: "10-14-2023"
---
# Problem 1: Instacart Grocery Large-Scale Data Analysis and Plotting

Begin by loading important libraries, organizing markdown, and beginning to pull in full dataset for exploratory data analysis. 

```{r}
library(tidyverse)
library(ggridges)
library(patchwork)
library(p8105.datasets)

data("instacart")

summary(instacart)

nrow(instacart)
ncol(instacart)

```

This is a large dataset that contains `r nrow(instacart)` rows of observations and `r ncol(instacart)` column variables. Each row is a specific instacart product - with associated department and aisle information. There are also categorical variables that describe the time and day of the order, and number of day since the previous order. 

In total, there are `r instacart |> select(product_id) |> distinct() |> count()` products found in `r instacart |> select(user_id, order_id) |> distinct() |> count()` orders from `r instacart |> select(user_id) |> distinct() |> count()` distinct users.

### Task 1 - How many aisles are there, and which aisles are the most items ordered from?**

```{r}

num = instacart |> 
  distinct(aisle_id) |> 
  max()

aisles_df = instacart |> 
  janitor::clean_names() |> 
  group_by(department, aisle) |> 
  summarize(n_obs = n()) |> 
  arrange(desc(n_obs))

aisles_df

```
There are **134 distinct aisles** across all the products instacart offers.
After creating a separate grouped tibble based on aisle name and the bulk total of orders from each aisle, we can see that the the top 3 aisles with the highest amount of items ordered are **Fresh Vegetables, Fresh Fruits, and Packaged Vegetables / Fruits.** These are then followed by Yogurt and Packaged Cheese in the dairy department. 

### Task 2 - Plotting Number of Items sold in Highest Demand Aisles**

```{r}
aisles_df |> 
  filter(n_obs >= 10000) |> 
  mutate(aisle = fct_reorder(aisle, n_obs)) |> 
  ggplot(aes(x=aisle, y = n_obs, fill = department)) + 
  geom_col() +
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle= 60, hjust = 1))

```

This column graph visualizes the relative quantities of items ordered across each aisle, color-coded by associated department. Internal to each department, the aisles are organized from least in demeand to most in demand items.

### Task 3 - Identifying Most Popular Items in Specific Aisles**

```{r}

popular_items = instacart |> 
  janitor::clean_names() |> 
  filter(aisle == "baking ingredients" | aisle == "dog food care" | aisle == "packaged vegetables fruits") |> 
  group_by(aisle, product_name) |> 
  summarize(n_obs = n()) |> 
  arrange(desc(n_obs)) |> 
  mutate(item_rank = min_rank(desc(n_obs))) |> 
  filter(item_rank < 4)
           
popular_items |> 
    knitr::kable(digits = 2)

```

This table above provides the top three most popular items in the requested aisles `baking ingredients`, `dog food care`, and `packaged vegetables fruits`. Because of the relative demand for produce across all orders, the packaged vegetable fruit orders are all much higher than the other two aisles of interest.

### Task 4 - Looking at weekly orders of two products

```{r}
Apple_Coffee = instacart |> 
  select(product_name, order_dow, order_hour_of_day) |> 
  group_by(product_name, order_dow) |> 
  filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") |> 
  mutate(
    order_dow = recode(
      order_dow,
      "0" = "Sunday",
      "1" = "Monday",
      "2" = "Tuesday",
      "3" = "Wednesday",
      "4" = "Thursday",
      "5" = "Friday",
      "6" = "Saturday")) |> 
  summarize(avg_hr = mean(order_hour_of_day)) |> 
  pivot_wider(
    names_from = order_dow,
    values_from = avg_hr)

Apple_Coffee |> 
    knitr::kable(digits = 2)
  
```

This final part of Problem 1 asks us to narrow the dataset down to just two procucts - Pink Lady Apples and Coffee Ice Cream, and look at there average times across the week. General trends show that during the work week, Apples are usually ordered earlier for lunch or snack while ice cream is ordered on average after work in the evening. Meanwhlile on the weekend Fri through Saturday, Ice cream and Apples have similar order times, being bought in the mid afternoon 12 to 1 pm for each product.


# Problem 2: Behavioral Risk Factors Dataset Analysis
Beginning by importing the dataset and doing initial steps to clean the tibble dataframe.
### Task 1 - Initial Data Cleaning
```{r}
data("brfss_smart2010")

brfss_clean = brfss_smart2010 |> 
  janitor::clean_names() |> 
  select(everything(), -data_value_unit, -data_value_footnote, -data_value_footnote_symbol, -location_id) |> 
  rename(state = locationabbr, county = locationdesc) |> 
  filter(topic == "Overall Health")

#Specific code to reorder response factor levels
brfss_clean = brfss_clean |> 
  mutate(response = as.factor(response)) |> 
  mutate(response = ordered(response, c("Poor", "Fair", "Good", "Very good", "Excellent")))
```
The original dataset before cleaning has `r nrow(brfss_smart2010)` rows of content, indicating a different question category from each state location, and `r ncol(brfss_smart2010)` column variables. 3 of these columns were entirely empty with NA's and were removed in the tidy dataset `brfss_clean`. Also one column `data_value_unit` was only describing that the unit was in percentages, and was removed to avoid confusion in calculations. 

For clarity, locationabbr and locationdesc were renamed to state and county respectively. After filtering only the Overall Health topic questions, and removign the extraneous columns identified above, this cleaned dataframe has `r nrow(brfss_clean)` rows and `r ncol(brfss_clean)` column variables.

The `response` column was converted from character to factor format, with five levels ordered from Poor -> Excellent as requested. 

### Task 2 - Analyzing Specific Response Data by Years

*Q: In 2002, which states were observed at 7 or more locations? What about in 2010?*

To do this, we will make two filtered subdataframes for both 2002 and 2010, that make tables containing 7 or more county locations for each state. This will use the `group_by` function. 

```{r}

largestates_2002 = brfss_clean |> 
  filter(year == 2002) |> 
  group_by(year, state) |> 
  summarize(n_locations = (n()/5)) |> 
  filter(n_locations >= 7) |> 
  arrange(desc(n_locations))
  

largestates_2002 |> 
  knitr::kable(digits = 2)
```
Because each distinct county will have the 5 levels of the response column for 1 entry, a state with 7 or more county locations can be identified by having 35 or more response entry levels.

In 2002, Six states - **Connecticut, Florida, Massachusetts, North Carolina, New Jersey, and Pennsylvania** - had responses coming from 7 or more distinct county locations. Pennsylvania had the highest capacity at 10 different locations (50/5 responses per location).

Below does the same exploratory data organization for the year 2010:

```{r}
largestates_2010 = brfss_clean |> 
  filter(year == 2010) |> 
  group_by(year, state) |> 
  summarize(n_locations = (n()/5)) |> 
  filter(n_locations >= 7) |> 
  arrange(desc(n_locations))

largestates_2010 |> 
  knitr::kable(digits = 2)
```
By 2010, we can see that **14 different states** have 7 or more distinct county locations covered by the response survey to Overall Health. The state with the most county representation in this year was Florida, with 41 distinct county locations reporting responses (205/5 response levels per location).

### Task 3 - Visualizing Excellent Health Responses across States over Time.

```{r}
#Organizing Dataframe
compare_excellent = brfss_clean |> 
  select(year, state, county, response, data_value) |> 
  filter(response == "Excellent") |> 
  group_by(year, state) |> 
  summarize(mean_excellent = mean(data_value)) |> 
  arrange(desc(mean_excellent))

compare_excellent

```

The cleaned dataframe `compare_excellent` is grouping by year and state, in order to average the excellent health response across all county locations of each state every year of the survey. 

The "Spaghetti" Plot below has lines for all 50 states in the survey from the colleciton range of 2002 - 2010. It contains `r nrow(compare_excellent)` from the `r ncol(compare_excellent)` columns of interest from the cleaned BRFSS dataset.

```{r}
#Creating Spaghetti Plot
compare_excellent |> 
  ggplot(aes(x = year, y = mean_excellent)) + 
           geom_line(alpha = 0.4, aes(group = state)) +
           geom_smooth() +
  labs(
    title = "Average Excellent Overall Health Response across all 50 States",
    x = "Year of Survey",
    y = "Avg. Excellent Response Percentage"
  )
  
```

The majority of states are within the range of 27% - 20% across the period. No state passes 30% excellent health, and the states at the lower extremities appears to be below 20%, with only 3 states crossing below 15% at any point in this study.

Looking at intra-state variation, there does seem to be a slight decline in excellent health response from 2002 through 2010 across most states, this may result from large-scale social events such as the 2008 financial crisis. 
`geom_smooth()` is used alongside `geom_line()` to get a blue general trendline of overall average excellent response percentage across all states in this timeframe. From this curve, we see an overall average of about 23.5% excellent in 2002, which falls down to about 21.5% excellent by 2005 and plateaus there, reaching about 21% in 2010. 

When arranging the dataframe to see the min and max of excellent responses, the lowest outlier state is the state of West Virginia, which only had a excellent health response of only **11.5 percent in the year 2005.** West Virginia is the most consistent low band in the Spaghetti Plot, followed by Indiana as second lowest. 

The highest states for average excellent health response over this time period appear to flunctuate considerably. Utah has the highest excellent response of 29.5% in 2002 but dips down to less than 25% by 2005. Connecticut appears to be relatively consistntly in the higher band of excellent percentages, starting 3rd highest at 29.1% in 2002. 

#### Task 4 - Health Response Distribution across NY State
*Q: Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.*

```{r}
#Creating NY State Dataframe and Boxplot Distribution
ny_response = brfss_clean |> 
  select(year, state, county, response, data_value) |> 
  filter(state == "NY" & year %in% c(2006, 2010))


ny_response |> 
  ggplot(aes(x= response, y = data_value)) + geom_boxplot(aes(fill= response), show.legend=FALSE) + 
  labs(
    title = "Distribution of Health Responses across NY State, 2006 vs. 2010",
    x = "Overall Health Response",
    y = "Percentage"
  ) +
  facet_grid(. ~ year)
```

This is a Boxplot visualization comparing the health responses recorded for NY State of the specific years of interest 2006 and 2010. The subframe filtered for these purposes had `r nrow(ny_response)` observations for the `r ncol(ny_response)` variable columns of interest.

The relative proportion of each of the 5 health response percentages are quite similar between the years, but there are some minor shifts. In 2010, there is a growing distribution of Poor and Fair Health responses. Very good has also moved higher in percentage distribution while both Good and Excellent have minutely decreased in distribution. It is unclear from this visualization if these changes are statistically significant, and could be a result of random error or the fact that a different number of county locations were sampled in 2010 than 2006 as the survey grew.

# Problem 3: NHANES Accelerometer Data Analysis

Begin by Importing and Cleaning the Two Separate CSVs for NHANES Demographics and Accelerometer information. The demographic covariate dataset has 4 lines of variable notes at the top of the spreadsheet and are removed when reading in the csv.

```{r}
demographic = read_csv("Data/nhanes_covar.csv", skip = 4) |> 
  janitor::clean_names() |> 
  drop_na() |> 
   mutate(
    sex = case_match(sex,
      1 ~ "male",
      2 ~ "female"),
    education = case_match(education,
      1 ~ "less than high school",
      2 ~ "high school",
      3 ~ "more than high school")) |> 
  filter(age >= 21)

accel_data = read_csv("Data/nhanes_accel.csv") |> 
  janitor::clean_names() |> 
  drop_na()

```

Dropping NA's from the demographics sheet brings the observations down to `r nrow(demographic)` study participants with complete data. Only 1 participant was excluded for being under 21 years of age. 

All data is complete in the accelerometer reporting datasheet, no NA's. SEQN ID will be used as key for joining.

### Task 1: Transforming Data and Completeing Table Join

```{r Transforming Data for Joining}

#Making Sex and Education Factors with Ordered Levels 
demographic = demographic |> 
  mutate(sex = as.factor(sex), education = as.factor(education)) |> 
  mutate(sex = ordered(sex, c("male", "female")), 
         education = ordered(education,
            c("less than high school", "high school", "more than high school")))

#Organizing Accel_data with Pivot_Longer
accel_data = accel_data |> 
  pivot_longer(
    min1:min1440,
    names_to = "minutes",
    names_prefix = "min",
    values_to = "mims_value") |> 
  mutate(minutes = as.numeric(minutes))

```

To prepare for visualization, each dataset is further tidied. The demographic covariates have their sex and education values changed from numerics to factors with ordered levels with rank, which will be used when plotting. Since the acceleromter has 1440 columns worth of mims readings each minute of a 24-hour day, a `pivot_longer` function was used to separate this into the minutes of time column and mims_values associated. 

The SEQN ID will now be used for an inner join with the demographic covariate dataframe:

```{r}
nhanes_df = inner_join(accel_data, demographic, by = "seqn")

```

This completed dataframe has a total of `r nrow(nhanes_df)` observations and `r ncol(nhanes_df)` variables of interest after the join by SEQN ID. 

### Task 2: Total Demographic Counts Sex and Education Status

The two factor level variables `sex` and `education` can be used to create a table of participant totals that is easy to read using the `group_by` function:

```{r}
participant_dist = demographic |> 
  select(seqn, age, sex, education) |> 
  group_by(sex, education) |> 
  summarize(participants = n())

participant_dist |> 
  knitr::kable(digits = 2)

```

This is a reader-accessible table highlighting organizing NHANES study participants by sex and education status. In this cohort, the educational status **"more than high school"** is the most represented for both men and women, with 59  female and 56 male participants making up about half of the entire 226 participant cohort. Similarly the least represented is participants with less than a high school degree, with 27 men and 28 women. There is a slightly skewed higher ratio of male participants with high school education (35) over high school educated females (28). 

```{r}
participant_ages = demographic |> 
  select(seqn, sex, age, education) |> 
  group_by(sex)

participant_ages |> 
  ggplot(aes(x = education, y = age, fill = sex)) + geom_boxplot() +
  labs(
    title = "NHANES Participant Age Distribution across Sex and Education",
    y = "Age in Years",
    x = "Education Status"
  ) +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 10))
```

In this boxplot visualization, we can see that female high school educated participants have a noticeably higher age distribution than males that are high school educated, with a median of 62 years for female vs 53 for male. More than high school educated seems to have the youngest distribution of ages across men and women, with a male median of 43 and female median of 41. Meanwhile the less than high school cohort has a median male age of 60 and a median female age of 61, an older cohort distribution across this educational status for both sexes.

### Task 4: Accelerometer MIMS Plots 

**Plot 1 Guidelines**

*Aggregate across minutes to create a total activity variable for each participant. Plot these total activities (y-axis) against age (x-axis); your plot should compare men to women and have separate panels for each education level. Include a trend line or a smooth to illustrate differences. Comment on your plot.*

```{r}
total_activity = nhanes_df |> 
  group_by(seqn) |> 
  mutate(mims_activity = sum(mims_value))
  
total_activity |> 
  ggplot(aes(x = age, y = mims_activity, color = sex)) +
  geom_point() + 
  geom_smooth(se = FALSE) + 
  labs(
    title = "NHANES Recorded MIMS Activity Across Participants, By Age and Education",
    y = "Total MIMS Activity",
    x = "Age in Years"
  ) +
  scale_x_continuous(breaks = scales::pretty_breaks()) +
  scale_color_hue(h = c(255, 8.5)) +
  facet_grid(. ~ education)
```

This scatterplot visualizaiton identifies the distribution of total MIMS activity from each participants accelerometer recordings, organized across participant age group, education level, and sex. 

`geom_smooth()` was used to produce trendlines across age groups for both sex cohorts. Across all three education statuses, there is a general decrease in recorded total activity as age increases. There is a higher overall range of activity in the 'less than high school' education cohort, with young women in their 20 -  30s having MIMS data around or above 20000. 

Across all three cohorts, young women appear to have more recorded activity than young men. The more than high school educational category has high variation but the trendlines with the consistently lower average activity at a younger age than the other two education groups. This may be due to the stationary nature of most white collar office jobs that are common to higher educated professionals.


**Plot 2 Guidelines** 

*Make a three-panel plot that shows the 24-hour activity time courses for each education level and use color to indicate sex. Including smooth trends may help identify differences*

```{r}
activity_time = nhanes_df |> 
  group_by(seqn)

activity_time |> 
  ggplot(aes(x = minutes, y = mims_value, color = sex)) +
  geom_line(alpha = 0.5) +
  geom_smooth(se = FALSE) +
  labs(
    title = "NHANES 24-hour Activity Time by Education Level, Sex",
    y = "Mims Activity Value",
    x = "Time (Minutes)"
  ) +
  scale_color_hue(h = c(255, 8.5)) +
  facet_grid(. ~ education) 

```

This supplemental graph isolates the average trendline below for male and female participants:

```{r}

activity_trendlines = activity_time |> 
  ggplot(aes(x = minutes, y = mims_value, color = sex)) +
  geom_smooth(se = FALSE) +
  labs(
    title = "Average Trendlines for NHANES 24-hour Activity Times",
    y = "Avg. Mims Activity",
    x = "Time (Minutes)"
  ) +
  scale_color_hue(h = c(255, 8.5)) +
  facet_grid(. ~ education) 

activity_trendlines

```
